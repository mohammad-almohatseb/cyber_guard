import asyncio
import logging
from fastapi import HTTPException
from urllib.parse import urlparse, parse_qs, urlunparse, urlencode

from app.api.models.information import WebInfoGatheringModel
from app.api.models.vuln_assessment import WebVulnerabilityAssessmentModel, NetworkVulnerabilityAssessmentModel
from app.api.models.vuln_exploiting import NetworkVulnerabilityExploitingModel, WebVulnerabilityExploitingModel

from app.api.exploiting.network.vsftpd_exploit import exploit_vsftpd_and_get_credentials
from app.api.exploiting.network.vnc_exploit import run_vnc_login_console
from app.api.exploiting.network.apache_tomact import exploit_tomcat_mgr

from app.api.exploiting.web.path_traversal import run_path_traversal_scan
from app.api.exploiting.web.cmdi import run_os_command_injection
from app.api.exploiting.web.xss_exploit import main as xss_main
from app.api.exploiting.web.redirect_exploit import test_urls_for_redirect
from app.api.exploiting.web.sql_exploit import sql_exploits

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Exploiting:
    def __init__(self):
        pass

    # ---------------- Network Data ----------------
    @staticmethod
    async def get_network_data(ip_address: str):
        return await NetworkVulnerabilityAssessmentModel.find_one(
            NetworkVulnerabilityAssessmentModel.target == ip_address
        )

    async def network_vulnerability_exploiting(self, ip_address: str):
        network_data = await self.get_network_data(ip_address)

        if network_data is None:
            raise HTTPException(status_code=404, detail="Network data not found")

        detected_services = network_data.detected_services_data or []
        vsftpd_exploiting_data = []
        vnc_exploiting_data = []
        apache_tomcat_data = []

        for item in detected_services:
            target = item.get("target")
            service = item.get("service", "").lower()

            if "ftp vsftpd 2.3.4" in service:
                result = await exploit_vsftpd_and_get_credentials(target)
                if result:
                    vsftpd_exploiting_data.append(result)

            if "vnc vnc (protocol 3.3)" in service:
                result = await run_vnc_login_console(target)
                if result:
                    vnc_exploiting_data.append({
                        "target": target,
                        "password": result
                    })

            normalized_service = " ".join(service.split())
            if "http apache tomcat/coyote jsp engine 1.1" in normalized_service:
                result = await exploit_tomcat_mgr(target)
                if result:
                    apache_tomcat_data.append(result)

        network_vuln_exploiting = NetworkVulnerabilityExploitingModel(
            target=ip_address,
            vsftpd_exploiting_data=vsftpd_exploiting_data,
            vnc_exploiting_data=vnc_exploiting_data,
            apache_tomcat_data=apache_tomcat_data
        )
        await network_vuln_exploiting.save()

    # ---------------- Web Data ----------------
    async def get_web_data(self, domain: str):
        return await WebVulnerabilityAssessmentModel.find_one(
            WebVulnerabilityAssessmentModel.target == domain
        )

    async def get_web_info_data(self, domain: str):
        return await WebInfoGatheringModel.find_one(
            WebInfoGatheringModel.target == domain
        )

    # ---------------- Web Exploiting ----------------
    def extract_clean_urls(self, all_expected_vulns: dict) -> dict:
        # Remove payload from the URLs
        cleaned_urls = {}

        for vuln_type, entries in all_expected_vulns.items():
            cleaned_list = []
            for entry in entries:
                url = entry.get("url")
                param = entry.get("parameter")
                if not url or not param:
                    continue

                parsed = urlparse(url)
                query = parse_qs(parsed.query)

                # Remove payload from the vulnerable parameter
                if param in query:
                    query[param] = ['']

                cleaned_query = urlencode({k: v[0] for k, v in query.items()})
                cleaned_url = urlunparse(parsed._replace(query=cleaned_query))
                cleaned_list.append(cleaned_url)

            cleaned_urls[vuln_type] = cleaned_list

        return cleaned_urls

    async def web_vulnerability_exploiting(self, domain: str):
        web_data = await self.get_web_data(domain)
        if web_data is None:
            raise HTTPException(status_code=404, detail="Web data not found")

        target = web_data.target

        # --- XSS Exploiting ---
        xss_info = web_data.all_expected_vulns.get("XSS", []) if web_data.all_expected_vulns else []
        xss_urls = [item.get("url") for item in xss_info if item.get("url")]

        logger.info(f"Running XSS Exploiting for target: {target}")
        xss_results = await xss_main(xss_urls)
        logger.info(f"XSS Exploiting completed for target: {target}")

        # --- Redirect Exploiting ---
        web_info_data = await self.get_web_info_data(domain)
        if web_info_data is None:
            raise HTTPException(status_code=404, detail="Web info data not found")

        archive_urls = getattr(web_info_data, "archive_urls", []) or []

        redirect_urls = []
        for obj in archive_urls:
            urls = obj.get("redirect_urls", [])
            if isinstance(urls, list):
                redirect_urls.extend(urls)
            else:
                logger.warning(f"Unexpected type for redirect_urls in archive: {type(urls)}")

        logger.info(f"Extracted {len(redirect_urls)} redirect URLs from archive data")

        if len(redirect_urls) == 0:
            logger.warning("No redirect URLs found to test.")

        logger.info(f"Running Redirect Exploiting for target: {target}")
        redirect_results = await test_urls_for_redirect(redirect_urls)
        logger.info(f"Redirect Exploiting completed for target: {target}")

        logger.info(f"Vulnerable URLs found: {len(redirect_results.get('vulnerable_urls', []))}")
        for url in redirect_results.get('vulnerable_urls', []):
            logger.info(f"[VULNERABLE] {url}")

        # --- SQL Injection Exploiting ---
        sql_info = web_data.all_expected_vulns.get("SQLI", []) if web_data.all_expected_vulns else []
        sql_urls = [item.get("url") for item in sql_info if item.get("url")]

        # Limit to only 1 URL
        sql_urls = sql_urls[:1]

        logger.info(f"Running SQLI Exploiting for target: {target}")

        sql_results = []
        for url in sql_urls:
            result = await sql_exploits(url)
            sql_results.extend(result)

        logger.info(f"SQLI Exploiting completed for target: {target}")

        # --- Path Traversal and CMDI Exploiting ---
        expected_vulns = web_data.all_expected_vulns or {}
        cleaned_urls_by_type = self.extract_clean_urls(expected_vulns)

        path_traversal_urls = cleaned_urls_by_type.get("PATH_TRAVERSAL", [])
        if not path_traversal_urls:
            logger.info(f"No PATH_TRAVERSAL vulnerabilities found for {target}")
        else:
            path_traversal_results = await run_path_traversal_scan(
                target_urls=path_traversal_urls,
                timeout=10,
                delay=0.1,
                max_concurrent=5
            )
        cmdi_urls = cleaned_urls_by_type.get("CMDI", [])
        if not cmdi_urls:
            logger.info(f"No CMDI vulnerabilities found for {target}")
            cmdi_results = []
        else:
            cmdi_results = await run_os_command_injection(
                target_urls=cmdi_urls,
                timeout=10,
                delay=0.1,
                max_concurrent=5
            )

        # --- Save exploitation results ---
        web_exploitation = WebVulnerabilityExploitingModel(
            target=target,
            xss_data=xss_results,
            redirect_data=[{"url": url} for url in redirect_results.get("open_redirect_results", [])],
            sql_injection_data=sql_results,
            path_traversal_data=path_traversal_results.get("findings", []) if path_traversal_urls else [],
            os_command_injection_data=cmdi_results
        )
        await web_exploitation.insert()
